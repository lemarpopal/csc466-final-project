# Lemar Popal

### Week 1 (02/25/2020-03/02/2020)
Wrote some Python code to get data from the Pushshift API. I originally wanted to get all comments for 2019, but I was only able to get about 31,500 comments (about 4 days worth of comments) before the API would started acting weird. So if there was error I would catch the it and continue the loop. I was able to get a week's worth of comments within a few minutes. Extrapolating for the entire year, there would be about 3 million comments total. This is roughly the same amount of comments between 2012 and 2018 (from the Kaggle dataset), so Wall Street Bets had a lot more activity in 2019 alone. 

I also worked with Anish and Adrien on the data exploration for the data we found on Kaggle. We looked at another repository (linked in the README) that did some preliminary analysis of comments from the data. In there was a useful algorithm that went through each comment and extracted the indicated position towards each stock ticker in a comment (puts, calls, buy, sell). Then did some visualization to see if the the number of puts, calls, buys, and sells in comments for Tesla (for example) was correlated to the actual performance of the stock. 

Next week we'll start implementing some of the ML models that Adrien suggested (Random Forest, XGBoost, etc.) to see if we can predict the price of a particular stock by the number of mentions in comments (and whether those mentions were puts, calls, buy, sell). 


### Week 2 (03/03/2020-03/10/2020)
This week I decided to fit some simple/naive models, like Decision Trees and Random Forests, to our comment data. I wrangled the X data into a form where each row consisted of a date (the comment was made), text of the comment, indications (whether to buy, sell, put, call), and score of the comment. The y (the value to predict for each row) was the average price of the stock over the next 3 days. For example, if a comment was made on 03/05/2018, the value to predict would be: [(high stock price 03/06/2018 + low 03/06/2018)/2 + (high stock price 03/07/2018 + low 03/07/2018)/2 + (high stock price 03/08/2018 + low 03/08/2018)/2]/3. I arbitrarily chose 3 days as the outlook for the stock price. It is very possible that WSB comments were predicting the price of Tesla stock for the next day (because an earning report was due to come out) or for the future weeks, months, or even years based on their own subjective opinions. If I had a large amount of time and computers I could probably try to predict for different date ranges. 

I chose to use the comment body as a feature because I thought the text  could have some qualities (like the type of words a user chooses to talk about a stock could mean that they are excited about the stock going up, or expecting it go down, etc) that would be beneficial to the model. Also, if a certain comment had a lot of indication to buy (or sell or ...) then that would be relevant to the model. Lastly I also used the score of the comment because if it was highly upvoted then people agree with it and it is probably more relevant to predict price. 

As for results, after cross validating the decision tree model had a RMSE of about 66. This means that it was about $66 off on average on stock price predictions. Obviosuly this is not a very good result because, on an average day, Tesla stock fluctuates much less than that. I also tried a Random Forest model and arbitrarily chose to use n_trees=200. However, the model took a prohibitively long amount of time to run and I anticipate it won't do much better than the decision tree. Perhaps a little better if I do some hyperparameter tuning (like a random grid search). 

Also, until this point I haven't talked about whether DT or RF are the *correct* models to use for the data we have. In fact they aren't, that's why I said they were naive models at the beginning. This is time series data where the price of a stock on a particular day is a function of the previous prices of the stock on past days. It doesn't just depend on the text of a comment or other features. 

Anish worked on creating an LSTM model which uses neural networks and is good for time-series forecasting. As expected, he got much better results for predicting the next day's stock price (RMSE of about $14). I'll try and work with Anish to see if we can predict stock prices for days farther out and see if it's better than an exponential moving average model. 

### Week 3 (03/11/2020-03/18/2020)
This week I got the Random Forest Regressor to work because I found out I had to limit the number of estimators and the max depth of the tree. After changing both those values to 10 it only took about a minute to complete a 10-fold cross validation. The RMSE was about $55, a decent improvement over the decision tree regressor. However, still much higher than the average change in Tesla's stock price per day (about $8.40). A grid search that varied some of the RF parameters did not yield much better results. 

As for the LSTM model, we found that it does not do nearly as well as the Exponential Moving Average model (EMA). The EMA The EMA is the sum of the stock's closing prices for the number of time periods in question, divided by that same number of periods, with greater weight and significance on the most recent stock prices. The EMA model had an RMSE of about 0.034 for predicting the next day's stock price. However, the EMA is usually *best* at predicting the next day's prices. It doesn't do as well for predicting farther out. 

We also found out that the LSTM does better *without* the comment data and just using the previous days' stock prices. The next thing we wanted to do was find out how much better LSTM does at predicting farther out prices versus the EMA. 
